{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6a3013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import argparse\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d98d0e",
   "metadata": {},
   "source": [
    "## Algorithm 1: Naive Paired Cost Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "903d7ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_files(directory):\n",
    "    \"\"\"\n",
    "    Parses all 'ipra_analysis_*.txt' files in a directory. This is done by\n",
    "    reading all files to build a complete model of the program's call graph\n",
    "    and register usage.\n",
    "    \"\"\"\n",
    "    callee_save_costs = {}\n",
    "    callee_call_sites = defaultdict(list)\n",
    "    function_hotness = {}\n",
    "\n",
    "    func_pattern = re.compile(r\"IPRA: Function: (.*?)\\[\")\n",
    "    usage_pattern = re.compile(r\"CSRegUsage: (.*?) IsFunctionEntryHot: (\\d+)\")\n",
    "    call_pattern = re.compile(r\"Calls: (.*?)\\[.*\\] IsTailCall: (\\d+).*? LivingCSRegs: (.*)\")\n",
    "    mbb_pattern = re.compile(r\"MBB: \\d+.*?MBBCount: (\\d+)\")\n",
    "\n",
    "    files_to_process = [os.path.join(directory, f) for f in os.listdir(directory) if f.startswith('ipra_analysis_') and f.endswith('.txt')]\n",
    "    print(f\"Found {len(files_to_process)} profile files to process.\")\n",
    "\n",
    "    for filepath in files_to_process:\n",
    "        with open(filepath, 'r', errors='ignore') as f:\n",
    "            current_function = None\n",
    "            current_mbb_count = 0\n",
    "            for line in f:\n",
    "                func_match = func_pattern.search(line)\n",
    "                if func_match:\n",
    "                    current_function = func_match.group(1).strip()\n",
    "                    current_mbb_count = 0\n",
    "\n",
    "                usage_match = usage_pattern.search(line)\n",
    "                if usage_match and current_function:\n",
    "                    regs_str = usage_match.group(1).strip()\n",
    "                    num_regs = len(regs_str.split()) if regs_str else 0\n",
    "                    callee_save_costs[current_function] = num_regs\n",
    "                    is_hot_str = usage_match.group(2).strip()\n",
    "                    function_hotness[current_function] = (int(is_hot_str) == 1)\n",
    "                \n",
    "                mbb_match = mbb_pattern.search(line)\n",
    "                if mbb_match:\n",
    "                    current_mbb_count = int(mbb_match.group(1))\n",
    "\n",
    "                call_match = call_pattern.search(line)\n",
    "                if call_match and current_function:\n",
    "                    callee_name = call_match.group(1).strip()\n",
    "                    live_regs_str = call_match.group(2).strip()\n",
    "                    num_live_regs = len(live_regs_str.split()) if live_regs_str else 0\n",
    "                    \n",
    "                    callee_call_sites[callee_name].append({\n",
    "                        \"caller\": current_function,\n",
    "                        \"live_csrs\": num_live_regs,\n",
    "                        \"count\": current_mbb_count\n",
    "                    })\n",
    "\n",
    "    print(f\"Found callee-save costs for {len(callee_save_costs)} unique functions.\")\n",
    "    print(f\"Found call sites for {len(callee_call_sites)} unique callees.\")\n",
    "    return callee_save_costs, callee_call_sites, function_hotness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3632898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_benefits(callee_save_costs, callee_call_sites, function_hotness):\n",
    "    \"\"\"\n",
    "    Calculates the total adjusted benefit score for each function.\n",
    "    \"\"\"\n",
    "    benefit_scores = defaultdict(int)\n",
    "    print(f\"Calculating benefit scores with Code Size Penalty = {size_penalty}...\")\n",
    "\n",
    "    # total_static_cost = 0\n",
    "\n",
    "    for callee, sites in callee_call_sites.items():\n",
    "        if not function_hotness.get(callee, False):\n",
    "            continue\n",
    "        callee_cost = callee_save_costs.get(callee, 0)\n",
    "        \n",
    "        total_dynamic_benefit = 0\n",
    "        sum_of_caller_costs = 0\n",
    "        \n",
    "        for site in sites:\n",
    "            caller_cost = site[\"live_csrs\"]\n",
    "            exec_count = site[\"count\"]\n",
    "            total_dynamic_benefit += (callee_cost - caller_cost) * exec_count\n",
    "            sum_of_caller_costs += caller_cost\n",
    "\n",
    "        # Calculate the total static cost (code size impact)\n",
    "        # It's the total number of new pushes/pops minus the ones removed.\n",
    "        # total_static_cost += 2 * (sum_of_caller_costs -  callee_cost)\n",
    "        \n",
    "        # Final adjusted score\n",
    "        adjusted_score = total_dynamic_benefit\n",
    "        benefit_scores[callee] = adjusted_score\n",
    "        \n",
    "    return benefit_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c3fd0b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parse_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m OUTPUT_FILE = \u001b[33m'\u001b[39m\u001b[33m/usr/local/google/home/tanjihui/Desktop/ipra-run/metrics/fdo_liveness_output/liveness_profdata.json\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      3\u001b[39m PRESERVE_NONE_THRESHOLD = \u001b[32m0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m costs, sites = \u001b[43mparse_files\u001b[49m(LIVENESS_DATA_DIR)\n\u001b[32m      6\u001b[39m scores = calculate_benefits(costs, sites, SIZE_PENALTY)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Filter for only positive scores, as negative scores are never beneficial\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'parse_files' is not defined"
     ]
    }
   ],
   "source": [
    "LIVENESS_DATA_DIR = '/usr/local/google/home/tanjihui/Desktop/ipra-run/metrics/fdo_liveness_output'\n",
    "OUTPUT_FILE = '/usr/local/google/home/tanjihui/Desktop/ipra-run/metrics/fdo_liveness_output/liveness_profdata.json'\n",
    "PRESERVE_NONE_THRESHOLD = 0\n",
    "# SIZE_PENALTY = 0.1\n",
    "\n",
    "costs, sites, function_hotness = parse_files(LIVENESS_DATA_DIR)\n",
    "scores = calculate_benefits(costs, sites, function_hotness)\n",
    "\n",
    "# Filter for only positive scores, as negative scores are never beneficial\n",
    "positive_scores = {func: score for func, score in scores.items() if score > PRESERVE_NONE_THRESHOLD}\n",
    "\n",
    "# Structure the final JSON and sort by score for easy inspection\n",
    "output_data = {\n",
    "    \"functions\": dict(sorted(positive_scores.items(), key=lambda item: item[1], reverse=True))\n",
    "}\n",
    "\n",
    "with open(OUTPUT_FILE, 'w') as f:\n",
    "    json.dump(output_data, f, indent=2)\n",
    "\n",
    "print(f\"\\n✅ Successfully merged profile data into '{OUTPUT_FILE}'\")\n",
    "print(f\"Found {len(positive_scores)} functions with a positive benefit score.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f884aa6",
   "metadata": {},
   "source": [
    "## Algorithm 2: Propagating Costs via Bottom-Up Call Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff3068ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_files(directory):\n",
    "    \"\"\"\n",
    "    Parses all 'ipra_analysis_*.txt' files in a directory to build a model\n",
    "    of the program's call graph and register usage.\n",
    "    \"\"\"\n",
    "    callee_save_costs = {}\n",
    "    function_hotness = {} # Store hotness for each function\n",
    "    callee_call_sites = defaultdict(list)\n",
    "    # The call graph is represented as Caller -> set(Callees)\n",
    "    successors = defaultdict(set)\n",
    "    predecessors = defaultdict(set)\n",
    "\n",
    "    func_pattern = re.compile(r\"IPRA: Function: (.*?)\\[\")\n",
    "    usage_pattern = re.compile(r\"CSRegUsage: (.*?) IsFunctionEntryHot: (\\d+)\")\n",
    "    call_pattern = re.compile(r\"Calls: (.*?)\\[.*\\] IsTailCall: (\\d+).*? LivingCSRegs: (.*)\")\n",
    "    mbb_pattern = re.compile(r\"MBB: \\d+.*?MBBCount: (\\d+)\")\n",
    "\n",
    "    files_to_process = [os.path.join(directory, f) for f in os.listdir(directory) if f.startswith('ipra_analysis_') and f.endswith('.txt')]\n",
    "    print(f\"Found {len(files_to_process)} profile files to process.\")\n",
    "\n",
    "    all_functions = set()\n",
    "\n",
    "    for filepath in files_to_process:\n",
    "        with open(filepath, 'r', errors='ignore') as f:\n",
    "            current_function = None\n",
    "            current_mbb_count = 0\n",
    "            for line in f:\n",
    "                func_match = func_pattern.search(line)\n",
    "                if func_match:\n",
    "                    current_function = func_match.group(1).strip()\n",
    "                    all_functions.add(current_function)\n",
    "                    current_mbb_count = 0\n",
    "\n",
    "                usage_match = usage_pattern.search(line)\n",
    "                if usage_match and current_function:\n",
    "                    regs_str = usage_match.group(1).strip()\n",
    "                    num_regs = len(regs_str.split()) if regs_str else 0\n",
    "                    callee_save_costs[current_function] = num_regs\n",
    "                    is_hot_str = usage_match.group(2).strip()\n",
    "                    function_hotness[current_function] = (int(is_hot_str) == 1)\n",
    "                \n",
    "                mbb_match = mbb_pattern.search(line)\n",
    "                if mbb_match:\n",
    "                    current_mbb_count = int(mbb_match.group(1))\n",
    "\n",
    "                call_match = call_pattern.search(line)\n",
    "                if call_match and current_function:\n",
    "                    callee_name = call_match.group(1).strip()\n",
    "                    is_tail_call_str = call_match.group(2).strip()\n",
    "                    \n",
    "                    all_functions.add(callee_name)\n",
    "                    live_regs_str = call_match.group(2).strip()\n",
    "                    num_live_regs = len(live_regs_str.split()) if live_regs_str else 0\n",
    "                    \n",
    "                    callee_call_sites[callee_name].append({\n",
    "                        \"caller\": current_function,\n",
    "                        \"live_csrs\": num_live_regs,\n",
    "                        \"count\": current_mbb_count,\n",
    "                        \"is_tail_call\": (int(is_tail_call_str) == 1) # Store tail call info\n",
    "                    })\n",
    "                    successors[current_function].add(callee_name)\n",
    "                    predecessors[callee_name].add(current_function)\n",
    "\n",
    "    print(f\"Found {len(all_functions)} unique functions in the call graph.\")\n",
    "    return callee_save_costs, callee_call_sites, successors, predecessors, all_functions, function_hotness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21a550c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topological_sort(nodes, successors, predecessors):\n",
    "    \"\"\"\n",
    "    Performs a topological sort (Kahn's algorithm) to get a bottom-up\n",
    "    processing order.\n",
    "    \"\"\"\n",
    "    in_degree = {node: len(predecessors[node]) for node in nodes}\n",
    "    queue = [node for node in nodes if in_degree[node] == 0]\n",
    "    sorted_nodes = []\n",
    "\n",
    "    while queue:\n",
    "        node = queue.pop(0)\n",
    "        sorted_nodes.append(node)\n",
    "        for successor in sorted(list(successors[node])): # sort for determinism\n",
    "            in_degree[successor] -= 1\n",
    "            if in_degree[successor] == 0:\n",
    "                queue.append(successor)\n",
    "    \n",
    "    # If there's a cycle, not all nodes will be in the sorted list.\n",
    "    if len(sorted_nodes) != len(nodes):\n",
    "        print(\"Warning: Cycle detected in the call graph. Some functions may not be processed.\")\n",
    "        # Add remaining nodes to the end to ensure they are processed.\n",
    "        remaining_nodes = [n for n in nodes if n not in sorted_nodes]\n",
    "        sorted_nodes.extend(remaining_nodes)\n",
    "\n",
    "    return sorted_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26565542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_benefits_bottom_up(callee_save_costs, callee_call_sites, successors, predecessors, all_functions, function_hotness, size_penalty, threshold):\n",
    "    \"\"\"\n",
    "    Calculates benefit scores using a bottom-up traversal of the call graph\n",
    "    to model the cascading effects of the preserve_none optimization.\n",
    "    \"\"\"\n",
    "    sorted_nodes = topological_sort(all_functions, successors, predecessors)\n",
    "    print(f\"Topologically sorted {len(sorted_nodes)} functions for bottom-up processing.\")\n",
    "\n",
    "    final_candidates = set()\n",
    "    # This dictionary simulates how a caller's own save cost might increase\n",
    "    # as its callees become preserve_none.\n",
    "    effective_cs_usage = defaultdict(int, callee_save_costs)\n",
    "    final_scores = {}\n",
    "\n",
    "    for callee in sorted_nodes:\n",
    "        # Skip any non-hot function:\n",
    "        if not function_hotness.get(callee, False):\n",
    "            final_scores[callee] = float('-inf')\n",
    "            continue\n",
    "\n",
    "        # 1. Calculate the benefit for the current function using the most up-to-date\n",
    "        #    cost information for itself and its callees.\n",
    "        callee_cost = effective_cs_usage[callee]\n",
    "        total_dynamic_benefit = 0\n",
    "        sum_of_caller_costs = 0\n",
    "        \n",
    "        call_sites = callee_call_sites.get(callee, [])\n",
    "        for site in call_sites:\n",
    "            if site.get(\"is_tail_call\", False):\n",
    "                continue\n",
    "            caller_cost = site[\"live_csrs\"]\n",
    "            exec_count = site[\"count\"]\n",
    "            total_dynamic_benefit += (callee_cost - caller_cost) * exec_count\n",
    "            sum_of_caller_costs += caller_cost\n",
    "\n",
    "        total_static_cost = (2 * sum_of_caller_costs) - (2 * callee_cost)\n",
    "        adjusted_score = total_dynamic_benefit - (size_penalty * total_static_cost)\n",
    "        final_scores[callee] = adjusted_score\n",
    "\n",
    "        # 2. Make a decision for the current function.\n",
    "        if adjusted_score > 0:\n",
    "            final_candidates.add(callee)\n",
    "            \n",
    "            # 3. Propagate the cost of this decision upwards to its callers.\n",
    "            #    We assume the cost pushed up is the original, static number of\n",
    "            #    registers the callee was responsible for.\n",
    "            original_callee_cost = callee_save_costs.get(callee, 0)\n",
    "            for caller in predecessors[callee]:\n",
    "                # This simulates the increased register pressure on the caller.\n",
    "                effective_cs_usage[caller] += original_callee_cost\n",
    "\n",
    "    return {func: score for func, score in final_scores.items() if func in final_candidates and score > threshold}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf1dc0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dangerous_functions(func_dict):\n",
    "    removed_list = []\n",
    "    for func in func_dict:\n",
    "        if func.startswith(\"_ZNSt\") or func.startswith(\"_ZSt\") or func.startswith(\"_ZN4llvm\") or func.startswith(\"_ZNK4llvm\") or not func.startswith(\"_Z\"):\n",
    "            removed_list.append(func)\n",
    "    for func in removed_list:\n",
    "        func_dict.pop(func)\n",
    "    return func_dict\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6416cb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1753 profile files to process.\n",
      "Found 82916 unique functions in the call graph.\n",
      "Warning: Cycle detected in the call graph. Some functions may not be processed.\n",
      "Topologically sorted 82916 functions for bottom-up processing.\n",
      "Found 1239 candidate functions meeting the threshold.\n"
     ]
    }
   ],
   "source": [
    "LIVENESS_DATA_DIR = './thinly_linked_fdo_liveness_output'\n",
    "SIZE_PENALTY = 0.1\n",
    "PRESERVE_NONE_THRESHOLD = 0\n",
    "\n",
    "costs, sites, successors, predecessors, all_nodes, function_hotness = parse_files(LIVENESS_DATA_DIR)\n",
    "candidate_scores = calculate_benefits_bottom_up(costs, sites, successors, predecessors, all_nodes, function_hotness, SIZE_PENALTY, PRESERVE_NONE_THRESHOLD)\n",
    "\n",
    "output_data = dict(sorted(candidate_scores.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "print(f\"Found {len(candidate_scores)} candidate functions meeting the threshold.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7e98f8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optional: try filtering out some core functions to avoid compilation failure\n",
    "# before_len = len(output_data)\n",
    "# output_data = filter_dangerous_functions(output_data)\n",
    "# after_len = len(output_data)\n",
    "# print(f\"Filtered out {before_len - after_len} functions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b79cd502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Successfully merged profile data into './thinly_linked_fdo_liveness_profdata.json'\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_FILE = './thinly_linked_fdo_liveness_profdata.json'\n",
    "output_dict = {\"functions\": output_data}\n",
    "with open(OUTPUT_FILE, 'w') as f:\n",
    "    json.dump(output_dict, f, indent=2)\n",
    "\n",
    "print(f\"\\n✅ Successfully merged profile data into '{OUTPUT_FILE}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a0981f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
